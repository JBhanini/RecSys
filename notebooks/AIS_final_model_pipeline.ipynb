{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "270.1875px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "AIS_model-pipeline.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQpNNwcPlc3e"
      },
      "source": [
        "# TODO\n",
        "- Implement the evaluate and benchmarking_pipeline functions\n",
        "- Extract all the notebook functions in a python script\n",
        "- Create a new notebook where you will use the extracted benchmarking_pipeline function to do the benchamrking\n",
        "- Do the benchmarking of the 5 already used models along with NMF and SVD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUSt05kylc3h"
      },
      "source": [
        "http://surpriselib.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPkpAsqJlc3i"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klHo1bIqlc3j"
      },
      "source": [
        "## From surprise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zr3d0lclj6I",
        "outputId": "3dc10eef-54b6-415d-d9a2-38771ec264d5"
      },
      "source": [
        "!pip install surprise"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting surprise\n",
            "  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/37/5d334adaf5ddd65da99fc65f6507e0e4599d092ba048f4302fe8775619e8/scikit-surprise-1.1.1.tar.gz (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 356kB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp36-cp36m-linux_x86_64.whl size=1618270 sha256=f7dc36c5d16ba19ec21729186ec67926c6521f0c96be3f9c5e5cce8fcf635d00\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/9c/3d/41b419c9d2aff5b6e2b4c0fc8d25c538202834058f9ed110d0\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGyyVTTrlc3k",
        "outputId": "8cc98e4c-d4c1-4f01-bd3f-8cd961bbf62d"
      },
      "source": [
        "from surprise import Dataset\n",
        "\n",
        "ratings = Dataset.load_builtin('ml-100k')\n",
        "ratings"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] y\n",
            "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.dataset.DatasetAutoFolds at 0x7f6e26832d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CdL1k9slc3m"
      },
      "source": [
        "## From file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5YHjdO7lc3o",
        "outputId": "e9256ba1-d8e6-415b-bd84-ce8c929394fa"
      },
      "source": [
        "from pathlib import Path\n",
        "from surprise import Reader\n",
        "\n",
        "ratings_filepath = Path('../content/ratings.csv')\n",
        "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
        "ratings = Dataset.load_from_file(ratings_filepath, reader)\n",
        "ratings"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.dataset.DatasetAutoFolds at 0x7f6e249a6940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_HulELQlc3p"
      },
      "source": [
        "## Modular function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu8s-hi0lc3p",
        "outputId": "38a6bb67-4e16-4f4a-c182-a032e5a15bda"
      },
      "source": [
        "from surprise.dataset import DatasetAutoFolds\n",
        "from pathlib import Path\n",
        "\n",
        "def load_ratings_from_surprise() -> DatasetAutoFolds:\n",
        "    ratings = Dataset.load_builtin('ml-100k')\n",
        "    return ratings\n",
        "\n",
        "def load_ratings_from_file(ratings_filepath : Path) -> DatasetAutoFolds:\n",
        "    reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
        "    ratings = Dataset.load_from_file(ratings_filepath, reader)\n",
        "    return ratings\n",
        "\n",
        "\n",
        "def get_ratings(load_from_surprise : bool = True, ratings_filepath : Path = None) -> DatasetAutoFolds:\n",
        "    if load_from_surprise:\n",
        "        ratings = load_ratings_from_surprise()\n",
        "    else:\n",
        "        ratings = load_ratings_from_file(ratings_filepath)\n",
        "    return ratings\n",
        "\n",
        "ratings = get_ratings(load_from_surprise=True)\n",
        "ratings"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.dataset.DatasetAutoFolds at 0x7f6e22e83320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVtTL0oPlc3q"
      },
      "source": [
        "# Manual pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8mozCaDlc3q"
      },
      "source": [
        "## Split data in train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvHS07oSlc3r",
        "outputId": "e04a325f-161d-4453-9945-2bc7a01b33ff"
      },
      "source": [
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "trainset, testset = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "trainset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.trainset.Trainset at 0x7f6e364a0cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us8npIgWlc3r"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWy0qb_Flc3r"
      },
      "source": [
        "from surprise import KNNBasic\n",
        "\n",
        "model = KNNBasic(sim_options={'user_based': True})"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seYGM4ASlc3s",
        "outputId": "6c0b8b31-cf0d-4d0d-e474-a556fed94e04"
      },
      "source": [
        "model.fit(trainset)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.knns.KNNBasic at 0x7f6e249a6630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-kLPytUlc3s",
        "outputId": "a296aaf4-c607-4e7f-beef-3f9618837633"
      },
      "source": [
        "from surprise.trainset import Trainset\n",
        "from  surprise.prediction_algorithms.algo_base import AlgoBase\n",
        "\n",
        "from surprise.prediction_algorithms.knns import KNNBasic\n",
        "\n",
        "def train(model_class: AlgoBase, model_arguments: dict, trainset: Trainset) -> AlgoBase:\n",
        "    model = model_class(model_arguments)\n",
        "    model.fit(trainset)\n",
        "    return model\n",
        "    \n",
        "trained(KNNBasic, {'user_based': False, 'name': 'pearson'}, trainset)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.knns.KNNBasic at 0x7f6e052f0d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH6qJaYHlc3t",
        "outputId": "ad885330-398d-4de1-e2da-73146781dce6"
      },
      "source": [
        "from surprise.prediction_algorithms.matrix_factorization import NMF\n",
        "\n",
        "train(NMF, 10, trainset)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.NMF at 0x7f6e0ac8f080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwwXQf3ulc3t"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIxgX5t1lc3t",
        "outputId": "37419829-12e8-47de-bcdd-57695fd1d91e"
      },
      "source": [
        "from surprise import accuracy\n",
        "\n",
        "predictions = model.test(testset)\n",
        "predictions[:10]\n",
        "\n",
        "accuracy.rmse(predictions=predictions)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.9802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.980150596704479"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtRJuwvPlc3u",
        "outputId": "c60f00da-3499-4227-97b1-559dac9e5554"
      },
      "source": [
        "accuracy.mae(predictions=predictions)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE:  0.7727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7726923699816388"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amTlI34jnx6O"
      },
      "source": [
        "from surprise import accuracy\r\n",
        "\r\n",
        "def evaluate(model: AlgoBase, test_set: [(int, int, float)]) -> dict:\r\n",
        "    predictions = model.test(test_set)\r\n",
        "    metrics_dict = {}\r\n",
        "    metrics_dict['RMSE'] = accuracy.rmse(predictions, verbose=False)\r\n",
        "    metrics_dict['MAE'] = accuracy.mae(predictions, verbose=False)\r\n",
        "    return metrics_dict"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56JlvdgYlc3u"
      },
      "source": [
        "## Modular code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKPadkMvlc3u",
        "outputId": "34b32705-5894-44da-d9c8-dfe82a8e2f15"
      },
      "source": [
        "from surprise.model_selection import train_test_split\r\n",
        "\r\n",
        "\r\n",
        "from surprise.prediction_algorithms.knns import KNNBasic\r\n",
        "\r\n",
        "def train_and_evalute_model_pipeline(model_class: AlgoBase, model_kwargs: dict = {},\r\n",
        "                                     from_surprise: bool = True,\r\n",
        "                                     test_size: float = 0.2) -> (AlgoBase, dict):\r\n",
        "    data = get_ratings(from_surprise)\r\n",
        "    train_set, test_set = train_test_split(data, test_size, random_state=42)\r\n",
        "    model = get_trained_model(model_class, model_kwargs, train_set)\r\n",
        "    metrics_dict = evaluate_model(model, test_set)\r\n",
        "    return model, metrics_dict\r\n",
        "\r\n",
        "my_model, metrics_dict = train_and_evalute_model_pipeline(KNNBasic)\r\n",
        "metrics_dict"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MAE': 0.980150596704479, 'RMSE': 0.980150596704479}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se_eTsS7lc3u"
      },
      "source": [
        "# Benchmarking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUo1Lwyslc3v",
        "outputId": "b2858aee-d286-474a-8702-d23555988e63"
      },
      "source": [
        "from surprise.prediction_algorithms.knns import KNNBasic\n",
        "\n",
        "benchmark_dict = {}\n",
        "\n",
        "model_kwargs = {'user_based': True, 'name': 'cosine'}\n",
        "knn, metrics_dict = train_and_evalute_model_pipeline(KNNBasic, model_kwargs)\n",
        "benchmark_dict['KNN user based cosine'] = metrics_dict\n",
        "\n",
        "model_kwargs = {'user_based': True, 'name': 'pearson'}\n",
        "knn, metrics_dict = train_and_evalute_model_pipeline(KNNBasic, model_kwargs)\n",
        "benchmark_dict['KNN user based pearson'] = metrics_dict\n",
        "\n",
        "model_kwargs = {'user_based': False, 'name': 'cosine'}\n",
        "knn, metrics_dict = train_and_evalute_model_pipeline(KNNBasic, model_kwargs)\n",
        "benchmark_dict['KNN item based cosine'] = metrics_dict\n",
        "\n",
        "model_kwargs = {'user_based': False, 'name': 'pearson'}\n",
        "knn, metrics_dict = train_and_evalute_model_pipeline(KNNBasic, model_kwargs)\n",
        "benchmark_dict['KNN item based pearson'] = metrics_dict\n",
        "\n",
        "\n",
        "benchmark_dict"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'KNN item based cosine': {'MAE': 1.0264295933767333,\n",
              "  'RMSE': 1.0264295933767333},\n",
              " 'KNN item based pearson': {'MAE': 1.041104054968961,\n",
              "  'RMSE': 1.041104054968961},\n",
              " 'KNN user based cosine': {'MAE': 1.0193536815834319,\n",
              "  'RMSE': 1.0193536815834319},\n",
              " 'KNN user based pearson': {'MAE': 1.0150350905205965,\n",
              "  'RMSE': 1.0150350905205965}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZmoVsARlc3v",
        "outputId": "8b6bfabe-ea53-4477-8d21-560897d8fdf1"
      },
      "source": [
        "benchmark_dict = {}\n",
        "\n",
        "model_dict_list = [\n",
        "    {\n",
        "        'model_name' : 'KNN user based with cosine similarity',\n",
        "        'model_class' : KNNBasic,\n",
        "        'model_kwargs' : {'user_based': True, 'name': 'cosine'}\n",
        "    },\n",
        "    {\n",
        "        'model_name' : 'KNN user based with pearson similarity',\n",
        "        'model_class' : KNNBasic,\n",
        "        'model_kwargs' : {'user_based': True, 'name': 'pearson'}\n",
        "    },\n",
        "\n",
        "    \n",
        "    {\n",
        "        'model_name' : 'KNN ratings based with cosine similarity',\n",
        "        'model_class' : KNNBasic,\n",
        "        'model_kwargs' : {'user_based': False, 'name': 'cosine'}\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model_name' : 'KNN ratings based with pearson similarity',\n",
        "        'model_class' : KNNBasic,\n",
        "        'model_kwargs' : {'user_based': False, 'name': 'pearson'}\n",
        "    },\n",
        "]\n",
        "\n",
        "for model_dict in model_dict_list:\n",
        "    model, metrics_dict = train_and_evalute_model_pipeline(\n",
        "        model_dict['model_class'], model_dict['model_kwargs'])\n",
        "    benchmark_dict[model_dict['model_name']] = metrics_dict\n",
        "    model_dict['fitted_model'] = model\n",
        "    \n",
        "benchmark_dict"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'KNN ratings based with cosine similarity': {'MAE': 1.0264295933767333,\n",
              "  'RMSE': 1.0264295933767333},\n",
              " 'KNN ratings based with pearson similarity': {'MAE': 1.041104054968961,\n",
              "  'RMSE': 1.041104054968961},\n",
              " 'KNN user based with cosine similarity': {'MAE': 1.0193536815834319,\n",
              "  'RMSE': 1.0193536815834319},\n",
              " 'KNN user based with pearson similarity': {'MAE': 1.0150350905205965,\n",
              "  'RMSE': 1.0150350905205965}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmQKjBBY81dQ",
        "outputId": "09204280-e6a4-41cc-8cb4-ccaa095018f7"
      },
      "source": [
        "from surprise.model_selection import cross_validate\r\n",
        "\r\n",
        "cross_validate(model, ratings, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    1.0366  1.0432  1.0415  1.0399  1.0449  1.0412  0.0029  \n",
            "MAE (testset)     0.8321  0.8330  0.8346  0.8348  0.8344  0.8338  0.0011  \n",
            "Fit time          2.44    2.48    2.46    2.50    2.45    2.47    0.02    \n",
            "Test time         4.12    4.19    4.15    4.09    4.17    4.14    0.04    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': (2.441161870956421,\n",
              "  2.4798202514648438,\n",
              "  2.457812786102295,\n",
              "  2.4984235763549805,\n",
              "  2.4494428634643555),\n",
              " 'test_mae': array([0.83207783, 0.83302573, 0.83464081, 0.83476846, 0.83444066]),\n",
              " 'test_rmse': array([1.03657392, 1.04321731, 1.04149756, 1.03991275, 1.04494219]),\n",
              " 'test_time': (4.122808218002319,\n",
              "  4.187647581100464,\n",
              "  4.146024942398071,\n",
              "  4.085706472396851,\n",
              "  4.1691601276397705)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    }
  ]
}